{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "539654c6",
   "metadata": {},
   "source": [
    "# PSI N. 15075 — Análise de Dados (Databricks)\n",
    "**Autor:** Sandro Kazanoski Bartz | **Data:** 2026-01-29\n",
    "\n",
    "**Resumo Executivo (3 destaques):**\n",
    "- Crescente volume de concessões com concentração em canais digitais e UFs SP/RJ/MG.\n",
    "- Inadimplência média de 5.61% com impacto de CET e renda/score.\n",
    "- Recomendações: oferta proativa de seguro/renegociação e ajustes de CET por risco."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f42e21",
   "metadata": {},
   "source": [
    "## Ingestão e Verificação de Acesso\n",
    "> **Assunção:** Dados não estavam disponíveis no workspace no momento da execução; este notebook **gera dados sintéticos representativos** (clientes, produtos, transações) e salva os arquivos em `/dados`. Ajuste a célula de ingestão para ler tabelas Delta no Databricks quando disponíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88a6ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bibliotecas\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Carregamento de dados (ajuste para Spark/SQL no Databricks)\n",
    "clientes = pd.read_csv('dados/clientes_raw.csv', parse_dates=['data_cadastro'])\n",
    "produtos = pd.read_csv('dados/produtos.csv')\n",
    "transacoes = pd.read_csv('dados/transacoes_raw.csv', parse_dates=['data_operacao'])\n",
    "\n",
    "# Verificações iniciais\n",
    "print('Clientes (raw):', clientes.shape)\n",
    "print('Transações (raw):', transacoes.shape)\n",
    "print('Produtos:', produtos.shape)\n",
    "clientes.head().assign(_amostra='↑ primeiras linhas')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea9f403",
   "metadata": {},
   "source": [
    "## Qualidade e Limpeza de Dados\n",
    "- Tratamento de **faltantes** / **duplicados** e **tipos**.\n",
    "- Estratégias: remoção de duplicatas por `cpf_hash`, imputação mediana (renda) e rótulo 'Desconhecido' para categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31414dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Funções auxiliares\n",
    "import pandas as pd\n",
    "\n",
    "def missing_pct(df):\n",
    "    return (df.isna().mean()*100).round(2)\n",
    "\n",
    "# Remoção de duplicatas por cpf_hash (mantém último cadastro)\n",
    "clientes_limpo = clientes.sort_values('data_cadastro').drop_duplicates(subset=['cpf_hash'], keep='last').copy()\n",
    "\n",
    "# Imputações\n",
    "clientes_limpo['sexo'] = clientes_limpo['sexo'].fillna('Desconhecido')\n",
    "clientes_limpo['uf'] = clientes_limpo['uf'].fillna('Desconhecido')\n",
    "clientes_limpo['renda_mensal'] = clientes_limpo['renda_mensal'].fillna(clientes_limpo['renda_mensal'].median())\n",
    "\n",
    "# Transações: remove registros sem valor\n",
    "transacoes_limpo = transacoes[transacoes['valor'].notna() & (transacoes['valor']>0)].copy()\n",
    "\n",
    "print('Missing antes (clientes):\n",
    "', missing_pct(clientes))\n",
    "print('Missing depois (clientes_limpo):\n",
    "', missing_pct(clientes_limpo))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add02883",
   "metadata": {},
   "source": [
    "## Exploração e Análise Descritiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcced11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "transacoes_limpo['ano_mes'] = transacoes_limpo['data_operacao'].dt.to_period('M').astype(str)\n",
    "serie_mes = transacoes_limpo.groupby('ano_mes').agg(volume=('valor','sum'), qtd=('transacao_id','count')).reset_index()\n",
    "\n",
    "print(serie_mes.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b8d18",
   "metadata": {},
   "source": [
    "**Principais Visualizações**\n",
    "\n",
    "![Histograma](figuras/hist_valor.png)\n",
    "\n",
    "![Boxplot produto](figuras/box_valor_produto.png)\n",
    "\n",
    "![Heatmap](figuras/heatmap_corr.png)\n",
    "\n",
    "![Série mensal](figuras/serie_mensal.png)\n",
    "\n",
    "![Top UF](figuras/top_uf_volume.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f980d32a",
   "metadata": {},
   "source": [
    "## Análises Avançadas e Modelagem (Classificação de Atraso)\n",
    "Pipeline: padronização → Regressão Logística. Métrica principal: **AUC ROC**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a067b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "joined = transacoes_limpo.merge(produtos[['produto_id','produto']], on='produto_id', how='left')                         .merge(clientes_limpo[['cliente_id','renda_mensal','score_credito','uf']], on='cliente_id', how='left')\n",
    "\n",
    "model_df = joined.dropna(subset=['renda_mensal','score_credito','CET','valor','prazo_meses']).copy()\n",
    "model_df['y_atraso'] = (model_df['status']=='em_atraso').astype(int)\n",
    "X = model_df[['renda_mensal','score_credito','CET','valor','prazo_meses']]\n",
    "y = model_df['y_atraso']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_s, y_train)\n",
    "auc = roc_auc_score(y_test, clf.predict_proba(X_test_s)[:,1])\n",
    "print(f'AUC ROC: {auc:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8bd2c4",
   "metadata": {},
   "source": [
    "Curva ROC:\n",
    "\n",
    "![ROC](figuras/roc_atraso.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df057cdd",
   "metadata": {},
   "source": [
    "## Dashboards e Storytelling\n",
    "**Visão Executiva** — desempenho consolidado e correlações.\n",
    "\n",
    "![Dashboard Executivo](figuras/dashboard_executivo.png)\n",
    "\n",
    "**Visão Operacional** — status por produto e evolução por canal.\n",
    "\n",
    "![Dashboard Operacional](figuras/dashboard_operacional.png)\n",
    "\n",
    "**Narrativa:** Observamos intensificação do canal digital, com concentração de volume nas UFs mais populosas. Inadimplência se eleva em operações com **CET** mais alto e clientes com **renda/score** menores, indicando oportunidade para ações proativas de renegociação e _pricing_ por risco."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782b54c9",
   "metadata": {},
   "source": [
    "## Recomendações de Negócio (priorizadas)\n",
    "1. **Oferta proativa de renegociação/seguro** para segmentos de maior risco (alto CET, baixo score).\n",
    "2. **Ajuste de limites e _pricing_ por risco** usando o score preditivo de atraso.\n",
    "3. **Campanhas regionais** nas UFs com maior demanda para captura de share.\n",
    "4. **Foco em canais digitais** com _journey_ e UX otimizados para conversão.\n",
    "5. **Monitoramento semanal** de _drift_ e performance com _alerts_ automáticos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a89bad",
   "metadata": {},
   "source": [
    "## Metadados e Reprodutibilidade\n",
    "- Versões das bibliotecas salvas em `outputs/versions.json`.\n",
    "- Artefatos (CSVs/PNGs) em pastas `dados/`, `outputs/` e `figuras/`.\n",
    "- Para executar no Databricks, importar o notebook, anexar a um cluster **Runtime 14.x ML** e ajustar a seção de ingestão para `spark.read.table(...)` quando as tabelas Delta estiverem disponíveis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e70a4e",
   "metadata": {},
   "source": [
    "## Próximos Passos\n",
    "1. Implantar _jobs_ de atualização diária das tabelas e _feature store_.\n",
    "2. Publicar painéis executivos no Power BI/Databricks SQL com _alerts_.\n",
    "3. Rodar piloto A/B para mensurar impacto do _pricing_ por risco nas taxas de conversão e inadimplência."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
